{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hola Rafael!\n",
    "\n",
    "Mi nombre es Matias y voy a estar revisando tu proyecto.\n",
    "\n",
    "En la primer revision, de encontrar errores voy a estar marcandotelos para que puedas corregirlos por tu cuenta. Lo mas parecido a una situacion real de trabajo como DA. De haber posteriores revisiones\n",
    "\n",
    "Encontraras mis comentarios debajo - **por favor no los muevas, modifiques o elimines**.\n",
    "\n",
    "Encontraras mis comentarios en verde, amarillo o rojo de esta manera:\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario de Revisor</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Genial, buen trabajo.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Comentario de Revisor</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Cuidado, se recomienda...\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "<b>Comentario de Revisor</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Necesita correcion. El trabajo no puede ser aceptado si precisa correcion.\n",
    "</div>\n",
    "\n",
    "Puedes responder a mis comentarios utilizando un mensaje de este tipo:\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Respuesta de estudiante.</b> <a class=\"tocSkip\"></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduccion al machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripción del proyecto\n",
    "La compañía móvil Megaline no está satisfecha al ver que muchos de sus clientes utilizan planes heredados. Quieren desarrollar un modelo que pueda analizar el comportamiento de los clientes y recomendar uno de los nuevos planes de Megaline: Smart o Ultra.\n",
    "\n",
    "Tienes acceso a los datos de comportamiento de los suscriptores que ya se han cambiado a los planes nuevos (del proyecto del curso de Análisis estadístico de datos). Para esta tarea de clasificación debes crear un modelo que escoja el plan correcto. Como ya hiciste el paso de procesar los datos, puedes lanzarte directo a crear el modelo.\n",
    "\n",
    "Desarrolla un modelo con la mayor exactitud posible. En este proyecto, el umbral de exactitud es 0.75. Usa el dataset para comprobar la exactitud.\n",
    "\n",
    "**Instrucciones del proyecto.**  \n",
    "1. Abre y examina el archivo de datos. Dirección al archivo: ***datasets/users_behavior.csv*** **Descarga el dataset**\n",
    "2. Segmenta los datos fuente en un conjunto de entrenamiento, uno de validación y uno de prueba.\n",
    "3. Investiga la calidad de diferentes modelos cambiando los hiperparámetros. Describe brevemente los hallazgos del estudio.\n",
    "4. Comprueba la calidad del modelo usando el conjunto de prueba.\n",
    "5. Tarea adicional: haz una prueba de cordura al modelo. Estos datos son más complejos que los que habías usado antes así que no será una tarea fácil. Más adelante lo veremos con más detalle.\n",
    "\n",
    "**Descripción de datos**  \n",
    "Cada observación en el dataset contiene información del comportamiento mensual sobre un usuario. La información dada es la siguiente:    \n",
    "* **сalls** — número de llamadas,\n",
    "* **minutes** — duración total de la llamada en minutos,\n",
    "* **messages** — número de mensajes de texto,\n",
    "* **mb_used** — Tráfico de Internet utilizado en MB,\n",
    "* **is_ultra** — plan para el mes actual (Ultra - 1, Smart - 0).  \n",
    "\n",
    "**Evaluación del proyecto**  \n",
    "Hemos definido los criterios de evaluación para el proyecto. Lee esto con atención antes de pasar al ejercicio.  \n",
    "Esto es lo que los revisores buscarán cuando evalúen tu proyecto:  \n",
    "¿Cómo leíste los datos después de descargarlos?  \n",
    "¿Segmentaste correctamente los datos en conjuntos de entrenamiento, validación y prueba?  \n",
    "¿Cómo escogiste el tamaño de los conjuntos?  \n",
    "¿Evaluaste correctamente la calidad del modelo?  \n",
    "¿Qué modelos e hiperparámentros usaste?  \n",
    "¿Cuáles fueron tus hallazgos?  \n",
    "¿Probaste los modelos correctamente?  \n",
    "¿Cuál es tu puntuación de exactitud?  \n",
    "¿Te ceñiste a la estructura del proyecto y mantuviste limpio el código?  \n",
    "Tienes tus hojas informativas y los resúmenes de los capítulos así que ya puedes continuar con el proyecto.  \n",
    "¡Buena suerte!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploracion de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerias a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verficación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_df(data):\n",
    "    data.info()\n",
    "    display(data.head())\n",
    "    print(data.isna().sum())\n",
    "    print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calls       0\n",
      "minutes     0\n",
      "messages    0\n",
      "mb_used     0\n",
      "is_ultra    0\n",
      "dtype: int64\n",
      "             calls      minutes     messages       mb_used     is_ultra\n",
      "count  3214.000000  3214.000000  3214.000000   3214.000000  3214.000000\n",
      "mean     63.038892   438.208787    38.281269  17207.673836     0.306472\n",
      "std      33.236368   234.569872    36.148326   7570.968246     0.461100\n",
      "min       0.000000     0.000000     0.000000      0.000000     0.000000\n",
      "25%      40.000000   274.575000     9.000000  12491.902500     0.000000\n",
      "50%      62.000000   430.600000    30.000000  16943.235000     0.000000\n",
      "75%      82.000000   571.927500    57.000000  21424.700000     1.000000\n",
      "max     244.000000  1632.060000   224.000000  49745.730000     1.000000\n"
     ]
    }
   ],
   "source": [
    "display_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que los tipos de datos estan correctos y no contamos con valores ausentes, tenemos 3214 entradas de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Respuesta de estudiante.</b> <a class=\"tocSkip\"></a>  \n",
    "\n",
    "Corregido\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario de Revisor</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Genial, buen comienzo.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Comentario de Revisor</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "A la funcion display_df que creaste seria bueno sumarle una linea mas que haga uso del metodo describe() de pandas para ver la distribucion de las variables numericas que tenga el dataset\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_rest = train_test_split(df, test_size = 0.40, random_state = 92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid, df_test = train_test_split(df_rest, test_size = 0.5, random_state = 92) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del conjunto de entranamiento: (1928, 5) en % respecto al conjunto original 60%\n",
      "Dimensiones del conjunto de validación: (643, 5) en % respecto al conjunto original 20%\n",
      "Dimensiones del conjunto de entranamiento: (643, 5) en % respecto al conjunto original 20%\n"
     ]
    }
   ],
   "source": [
    "print(f'Dimensiones del conjunto de entranamiento: {df_train.shape} en % respecto al conjunto original {(len(df_train)/len(df)):.0%}')\n",
    "print(f'Dimensiones del conjunto de validación: {df_valid.shape} en % respecto al conjunto original {(len(df_valid)/len(df)):.0%}')\n",
    "print(f'Dimensiones del conjunto de entranamiento: {df_test.shape} en % respecto al conjunto original {(len(df_test)/len(df)):.0%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos el conjunto de datos original en 3 partes:  \n",
    "* Conjunto de entramiento\n",
    "* Conjunto de validación\n",
    "* Conjunto de prueba  \n",
    "\n",
    "Se dividio con una relacion 3:1:1 es decir: el 60%, 20%, 20% respectivamente y lo podemos afirmar con la comprobación  \n",
    "\n",
    "Como bien sabemos, nuestro objetivo es recomendar el tipo de plan, por lo que dividiremos nuestros datos por sus caracteristicas/features y por su objetivo/target que en este caso seria el plan la cual su columna es **'is_ultra'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentacion de datos para el conjunto de entramiento\n",
    "train_features = df_train.drop(['is_ultra'], axis=1)\n",
    "train_target = df_train['is_ultra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentacion de datos para el conjunto de validación\n",
    "valid_features = df_valid.drop(['is_ultra'], axis=1)\n",
    "valid_target = df_valid['is_ultra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentacion de datos para el conjunto de prueba\n",
    "test_features = df_test.drop(['is_ultra'], axis=1)\n",
    "test_target = df_test['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos nuestras caracteristicas y nuestros objetivos para cada tipo de conjunto, pasaremos a realizar los modelos y ponerlos a prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario de Revisor</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Genial, buen trabajo con el split y separando las features de la variable objetivo\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo es recomendar un plan y en este caso tenemos plan smart(0) o ultra(1), por lo que tenemos un problema de clasificación, asi que haremos los modelos correspondientes para verificar cual es el más adecuado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbol de decisión - Tree decision classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeClassifier(random_state=92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_param = {\n",
    "    'max_depth' : [None, 10, 50, 100],\n",
    "    'min_samples_leaf' : [1,2]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1 = GridSearchCV(estimator = tree_model,\n",
    "                  param_grid = tree_param,\n",
    "                  cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=92),\n",
       "             param_grid={'max_depth': [None, 10, 50, 100],\n",
       "                         'min_samples_leaf': [1, 2]})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs1.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo: DecisionTreeClassifier(max_depth=10, min_samples_leaf=2, random_state=92)\n",
      "\n",
      "Mejores hiperparametros: {'max_depth': 10, 'min_samples_leaf': 2}\n",
      "\n",
      "Mejor puntuación 0.7806096494179396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Mejor modelo:',gs1.best_estimator_)\n",
    "print()\n",
    "print('Mejores hiperparametros:',gs1.best_params_)\n",
    "print()\n",
    "print('Mejor puntuación',gs1.best_score_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree_model = gs1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = best_tree_model.score(train_features, train_target)\n",
    "valid_score = best_tree_model.score(valid_features, valid_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuación del conjunto de entrenamiento de acuerdo al mejor modelo de arbol de decisión: 0.870850622406639\n",
      "Puntuación del conjunto de validación de acuerdo al mejor modelo de arbol de decisión: 0.7993779160186625\n"
     ]
    }
   ],
   "source": [
    "print('Puntuación del conjunto de entrenamiento de acuerdo al mejor modelo de arbol de decisión:',train_score)\n",
    "print('Puntuación del conjunto de validación de acuerdo al mejor modelo de arbol de decisión:',valid_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la prueba de score al conjunto de entramiento y de validación para saber si tenemos overfitting, a lo cual vemos que la puntuacion del conjunto de validacion si es mas baja en relación a la puntuacion del conjunto de entramiento alrededor de 8% o 0.08."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bosque aleatorio - Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_model = RandomForestClassifier(random_state=92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_param = {\n",
    "    'max_depth' : [None, 10, 50, 100],\n",
    "    'n_estimators' : [100,200,500],\n",
    "    'min_samples_leaf' : [1,2]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs2 = GridSearchCV(estimator = random_model,\n",
    "                  param_grid = random_param,\n",
    "                  cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=92),\n",
       "             param_grid={'max_depth': [None, 10, 50, 100],\n",
       "                         'min_samples_leaf': [1, 2],\n",
       "                         'n_estimators': [100, 200, 500]})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo de bosque aleatorio: RandomForestClassifier(max_depth=10, n_estimators=500, random_state=92)\n",
      "\n",
      "Mejores hiperparametros: {'max_depth': 10, 'min_samples_leaf': 1, 'n_estimators': 500}\n",
      "\n",
      "Mejor puntuación: 0.8137971872686898\n"
     ]
    }
   ],
   "source": [
    "print('Mejor modelo de bosque aleatorio:',gs2.best_estimator_)\n",
    "print()\n",
    "print('Mejores hiperparametros:',gs2.best_params_)\n",
    "print()\n",
    "print('Mejor puntuación:',gs2.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_forest_model = gs2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = best_forest_model.score(train_features, train_target)\n",
    "valid_score = best_forest_model.score(valid_features, valid_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuación del conjunto de entrenamiento de acuerdo al mejor modelo de bosque aleatorio: 0.899896265560166\n",
      "Puntuación del conjunto de validación de acuerdo al mejor modelo de bosque aleatorio: 0.8164852255054432\n"
     ]
    }
   ],
   "source": [
    "print('Puntuación del conjunto de entrenamiento de acuerdo al mejor modelo de bosque aleatorio:',train_score)\n",
    "print('Puntuación del conjunto de validación de acuerdo al mejor modelo de bosque aleatorio:',valid_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la prueba de score al conjunto de entramiento y de validación para saber si tenemos overfitting, a lo cual vemos que la puntuacion del conjunto de validacion es mas baja en relación a la puntuacion del conjunto de entramiento pero solo de 8% o 0.08."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresion logistica - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model = LogisticRegression(random_state=92,solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_param = {\n",
    "    'penalty' : ['l1', 'l2'],\n",
    "    'C' : [0.5, 1.0, 1.5, 2],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs3 = GridSearchCV(estimator = log_reg_model,\n",
    "                  param_grid = log_reg_param,\n",
    "                  cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(random_state=92, solver='liblinear'),\n",
       "             param_grid={'C': [0.5, 1.0, 1.5, 2], 'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs3.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo de regresión logistica: LogisticRegression(C=0.5, penalty='l1', random_state=92, solver='liblinear')\n",
      "\n",
      "Mejores hiperparametros: {'C': 0.5, 'penalty': 'l1'}\n",
      "\n",
      "Mejor puntuación: 0.7541578628625261\n"
     ]
    }
   ],
   "source": [
    "print('Mejor modelo de regresión logistica:',gs3.best_estimator_)\n",
    "print()\n",
    "print('Mejores hiperparametros:',gs3.best_params_)\n",
    "print()\n",
    "print('Mejor puntuación:',gs3.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_log_reg_model = gs3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = best_log_reg_model.score(train_features, train_target)\n",
    "valid_score = best_log_reg_model.score(valid_features, valid_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuación del conjunto de entrenamiento de acuerdo al mejor modelo de bosque aleatorio: 0.7567427385892116\n",
      "Puntuación del conjunto de validación de acuerdo al mejor modelo de bosque aleatorio: 0.7340590979782271\n"
     ]
    }
   ],
   "source": [
    "print('Puntuación del conjunto de entrenamiento de acuerdo al mejor modelo de bosque aleatorio:',train_score)\n",
    "print('Puntuación del conjunto de validación de acuerdo al mejor modelo de bosque aleatorio:',valid_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos la prueba de score al conjunto de entramiento y de validación para saber si tenemos overfitting, a lo cual vemos que la puntuacion del conjunto de validacion es mas baja en relación a la puntuacion del conjunto de entramiento pero solo de 2% o 0.02."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que el modelo que tiene una mayor puntiación/exactitud es el modelo de bosque aleatorio: RandomForestClassifier(max_depth=10, n_estimators=500, random_state=92)  \n",
    "\n",
    "Con una exactitud de:  \n",
    "0.899896265560166 para el conjunto de entramiento   \n",
    "0.8164852255054432 para el conjunto de validación\n",
    "\n",
    "Por lo que usaremos este modelo para hacer las predicciones con el conjunto de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Respuesta de estudiante.</b> <a class=\"tocSkip\"></a>  \n",
    "\n",
    "Corregido e implementado, se implemento GridSearchCV, es más practico a la hora de probar diferentes hiperparametros y mas sencillo de aplicar.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario de Revisor</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Veo que has entendido la logica detras de entrenar los modelos con diferentes hiperparametros y corroborar cual es la mejor opcion en funcion de la metrica accuracy\n",
    "    \n",
    "Hiciste un muy buen trabajo\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Comentario de Revisor</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Rafael, en este seccion te propongo 2 correcciones\n",
    "    \n",
    "Primero, para elegir cuales hiperparametros serian optimos esta bien hacerlo con una metrica sobre las predicciones en el split de validacion. \n",
    "    \n",
    "Pero tambien seria bueno que luego de haber encontrado el valor optimo de hiperparametros esa metrica la calcules tambien para el split train y test para comparar y concluir si estamos teniendo overfitting o no\n",
    "    \n",
    "Segundo, en vez de usar for loops, podrias usar el metodo Grid Search CV de la libreria sklearn y asi no solo probar con diferentes valores de 1 hiperparametro sino de 2 o mas hiperparametros a la vez.\n",
    "    \n",
    "Por ejemplo para\n",
    "    \n",
    "    - el arbol de decision con los hiperparametros max_depth y min_samples_leaf \n",
    "    \n",
    "    - el random forest con max_depth y n_estimators\n",
    "    \n",
    "    - la regresion logistica con penalty y C\n",
    "    \n",
    "Eso si, al usar este metodo no uses listas de valores de hipermarametros muy grandes porque sino se pondra muy lento el entrenamiento (situacion que en la realidad se traduce en un alto costo de computo)\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puesta a prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = best_forest_model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 1 1 1 1 0 0 0 1 0 0 0 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 0 1 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 1 0\n",
      " 1 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud de la prediccion es de 0.7931570762052877\n",
      "La precision del modelo es de 0.7426470588235294\n",
      "La sensibilidad del modelo es de 0.507537688442211\n"
     ]
    }
   ],
   "source": [
    "test_accu = accuracy_score(test_target, test_predict)\n",
    "test_precision = precision_score(test_target, test_predict)\n",
    "test_recall = recall_score(test_target, test_predict)\n",
    "print(f'La exactitud de la prediccion es de {test_accu}')\n",
    "print(f'La precision del modelo es de {test_precision}')\n",
    "print(f'La sensibilidad del modelo es de {test_recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo a nuestro modelo la prediccion de los datos del conjunto de prueba es del 79%  \n",
    "La precision nos indica el porcentaje que el modelo tomo como 1 en este caso seria el plan ultra respecto a los valores originales, lo cual nos da un 74.2% de precisión.  \n",
    "La sensibilidad nos indica el porcentaje que el modelo reconocio de los planes que estaban marcados como 1 plan ultra, que en este caso fue de 50.75%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Respuesta de estudiante.</b> <a class=\"tocSkip\"></a>  \n",
    "\n",
    "Corregido de hecho al final, las puntuaciones finales si variaron para bien, aunque no fue mucho, puntos son puntos.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario de Revisor</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Rafael, tu proyecto esta muy bien encarado es claro que comprendiste los conceptos y los aplicaste con buen codigo\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Comentario de Revisor</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Las correcciones propuestas son minimas y espero te lleven a ahondar un poco mas sobre herramientas de ML\n",
    "    \n",
    "Quedo a la espera de tu devolucion con estas para poder aprobar tu proyecto, vas por muy buen camino\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Comentario de Revisor - 2da ITERACION</b> <a class=\"tocSkip\"></a>\n",
    "\n",
    "Excelente trabajo Rafel, felicitaciones tu proyecto esta aprobado\n",
    "    \n",
    "Que bueno que hayas encontrado provechoso el uso de Grid Search y hayas podido implementar todas las correcciones propuestas\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "326.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
